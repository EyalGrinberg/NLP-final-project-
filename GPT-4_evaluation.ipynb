{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# libraries\n",
    "import pandas as pd\n",
    "import os\n",
    "import ast\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain.callbacks import get_openai_callback\n",
    "from tqdm.auto import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install --upgrade --quiet  langchain-google-genai pillow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"OPENAI_API_KEY\"] = \"hidden\"\n",
    "os.environ[\"ANTHROPIC_API_KEY\"] = \"hidden\"\n",
    "os.environ[\"GOOGLE_API_KEY\"] = \"hidden\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "OPENAI_API_KEY = os.environ.get(\"OPENAI_API_KEY\")\n",
    "ANTHROPIC_API_KEY = os.environ.get(\"ANTHROPIC_API_KEY\")\n",
    "GOOGLE_API_KEY = os.environ.get(\"GOOGLE_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = \"\"\"\n",
    "You have vast knowledge of python coding and libraries.\n",
    "You know the PEP257 docstring conventions.\n",
    "You can evaluate the quality of a docstring when given a code snippet and a corresponding docstring.\n",
    "\"\"\"\n",
    "my_prompt = \"\"\"\n",
    "Given the following code: {code}\n",
    "and the following generated docstring: {generated_docstring}\n",
    "Assess the quality of the generated docstring based on the following criteria:\n",
    "For each evaluation metric, rate the quality of the generated docstring on a scale of 0 to 100.\n",
    "The evaluation metrics are:\n",
    "1. Accuracy - How well does the docstring describe the code?\n",
    "2. Completeness - Does the docstring contain all the necessary information about the code?\n",
    "3. Relevance - The ability of the docstring to stick to the point and not include irrelevant information.\n",
    "4. Understandability - How easy is it for a reader to understand the docstring?\n",
    "5. Readability - How well is the docstring formatted and structured?\n",
    "Your response shoulde be only a python list of evaluation metrics [<Accuracy score>, <Completeness score>, <Relevance score>, <Understandability score>, <Readability score>],\n",
    "do not include any other information.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", system_prompt),\n",
    "    (\"user\", my_prompt),\n",
    "])\n",
    "\n",
    "llm_gpt_turbo = ChatOpenAI(openai_api_key=OPENAI_API_KEY, model=\"gpt-3.5-turbo\")\n",
    "\n",
    "output_parser = StrOutputParser()\n",
    "\n",
    "chain_solution_gpt_turbo = prompt | llm_gpt_turbo | output_parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_docstring(code, generated_docstring, chain_solution):\n",
    "    evaluation_response = chain_solution.invoke({\"code\": code, \"generated_docstring\": generated_docstring})\n",
    "    try: # try to convert the string to a list.\n",
    "        return ast.literal_eval(evaluation_response)\n",
    "    except (ValueError, SyntaxError):\n",
    "        raise ValueError(\"The model's response string is not a valid list representation.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 docstring evaluation with Gemini"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_for_gemini = ChatPromptTemplate.from_template(\n",
    "    system_prompt + my_prompt\n",
    ")\n",
    "\n",
    "data = pd.read_csv(\"function 10 all 3 models.csv\")\n",
    "function_10_code = data.loc[10, 'Function']\n",
    "gemini_docstring_function_10 = data.loc[10, 'Gemini']\n",
    "\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "llm_google = ChatGoogleGenerativeAI(google_api_key=GOOGLE_API_KEY, model=\"gemini-1.0-pro\")\n",
    "chain_solution_gemini = prompt_for_gemini | llm_google | output_parser\n",
    "\n",
    "generated_evaluation_list = evaluate_docstring(function_10_code, gemini_docstring_function_10, chain_solution_gemini)\n",
    "\n",
    "columns_to_add = ['Accuracy Gemini', 'Completeness Gemini', 'Relevance Gemini', 'Understandability Gemini', 'Readability Gemini']\n",
    "\n",
    "data.loc[10, columns_to_add] = generated_evaluation_list\n",
    "\n",
    "data.to_csv(\"gemini evaluation on gemini docstring.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 docstring evaluation with GPT 3.5 Turbo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[80, 80, 100, 90, 90]\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv(\"function 10 all 3 models.csv\")\n",
    "function_10_code = data.loc[10, 'Function']\n",
    "gpt_turbo_docstring_function_10 = data.loc[10, 'GPT-3.5 Turbo']\n",
    "\n",
    "generated_evaluation_list = evaluate_docstring(function_10_code, gpt_turbo_docstring_function_10, chain_solution_gpt_turbo)\n",
    "\n",
    "columns_to_add = ['Accuracy Gpt 3.5 Turbo', 'Completeness Gpt 3.5 Turbo', 'Relevance Gpt 3.5 Turbo', 'Understandability Gpt 3.5 Turbo', 'Readability Gpt 3.5 Turbo']\n",
    "\n",
    "data.loc[10, columns_to_add] = generated_evaluation_list\n",
    "\n",
    "data.to_csv(\"gpt 3.5 turbo evaluation on gpt 3.5 turbo docstring.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Docstrings evaluation for all models using GPT-4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"function 10 all 3 models.csv\") # load the data when all docstrings are generated\n",
    "\n",
    "llm_gpt4 = ChatOpenAI(openai_api_key=OPENAI_API_KEY, model=\"gpt-4-1106-Preview\")\n",
    "chain_solution_gpt4 = prompt | llm_gpt4 | output_parser\n",
    "\n",
    "models = ['T5 Baseline', 'GPT-3.5 Turbo', 'Claude-instant-1', 'Gemini-1.0-pro']\n",
    "\n",
    "tqdm.pandas()\n",
    "\n",
    "with get_openai_callback() as cb:\n",
    "    for model in models:\n",
    "        # Define the new columns to be added to the DataFrame\n",
    "        columns_to_add = ['Accuracy ' + model, 'Completeness ' + model, 'Relevance ' + model, 'Understandability ' + model, 'Readability ' + model]\n",
    "        \n",
    "        # Initialize the new columns with None values\n",
    "        data[columns_to_add] = None\n",
    "        \n",
    "        # Create a mask for rows where any of the new columns have missing values\n",
    "        missing_values_mask = data[columns_to_add].isna()\n",
    "        print(f\"Evaluating docstrings and filling columns {columns_to_add}...\")\n",
    "        \n",
    "        # Apply the function and update the DataFrame\n",
    "        data.loc[missing_values_mask, columns_to_add] = data.loc[missing_values_mask].progress_apply(\n",
    "            lambda row: pd.Series(evaluate_docstring(row['Function'], row[model], chain_solution_gpt4)),\n",
    "            axis=1\n",
    "        )\n",
    "        \n",
    "        # Debugging: Print the updated rows\n",
    "        print(data.loc[missing_values_mask, columns_to_add])\n",
    "\n",
    "print(cb)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
