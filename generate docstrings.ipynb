{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install openai == 0.28\n",
    "%pip install tiktoken\n",
    "%pip install tqdm\n",
    "%pip install matplotlib\n",
    "%pip install sympy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import openai\n",
    "import tiktoken\n",
    "from tqdm.auto import trange, tqdm\n",
    "import time\n",
    "import os\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "import re\n",
    "from types import NoneType\n",
    "import multiprocessing.dummy\n",
    "from io import StringIO\n",
    "from contextlib import redirect_stdout\n",
    "import signal\n",
    "from contextlib import contextmanager\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "import ast\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from IPython.display import display_latex\n",
    "from langchain.callbacks import get_openai_callback\n",
    "from tqdm.auto import tqdm\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LLM SETUP OPEN AI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "OPENAI_API_KEY = \"YOUR API KEY\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code generating prompts\n",
    "system_prompt = \"\"\"\n",
    "You are a helpful assistant, assinged with generating docstrings to python functions and classes. \n",
    "You have vast knowledge of python coding and libraries.\n",
    "You know the PEP8 coding conventions.\n",
    "\"\"\"\n",
    "my_prompt = \"\"\"\n",
    "Provide a good docstring to the following code: {code}\n",
    "Correct format example:\n",
    "code = \n",
    "\n",
    "def multiply_and_sum(lst):\n",
    "    res = 0\n",
    "    for i, item in enumerate(lst):\n",
    "        res += item * i \n",
    "    return res\n",
    "\n",
    "solution =\n",
    "\n",
    "    Iteratively computes the sum of all elements in a list of integers after multiplying each element by its index in the list.\n",
    "    Args:\n",
    "    - lst (list): a list of integers\n",
    "    Returns:\n",
    "    - int: the sum of all elements in the list after preforming the multipication of the elements by their indices.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import ChatPromptTemplate\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", system_prompt),\n",
    "    (\"user\", my_prompt),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "\n",
    "llm = ChatOpenAI(openai_api_key=OPENAI_API_KEY, model=\"gpt-4-1106-preview\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "output_parser = StrOutputParser()\n",
    "\n",
    "chain_solution = prompt | llm | output_parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_docstring_llm(code, docstring_col, chain_solution=chain_solution):\n",
    "    llm_docstring = chain_solution.invoke({\n",
    "        \"code\": code\n",
    "    })\n",
    "    return docstring_col, llm_docstring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"Benchmark database code chunks.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.callbacks import get_openai_callback\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "tqdm.pandas()\n",
    "\n",
    "with get_openai_callback() as cb:\n",
    "    new_docstring_col = 'new_docstring' # change col name for each model\n",
    "    data[new_docstring_col] = None\n",
    "    missing_values_mask = data[new_docstring_col].isna()\n",
    "    print(f\"Generating docstrings by {new_docstring_col}...\")\n",
    "    \n",
    "    data.loc[missing_values_mask, [new_docstring_col]] = (\n",
    "        data.loc[missing_values_mask, 'Function'].progress_apply(\n",
    "            lambda x: generate_docstring_llm(x, new_docstring_col)[1]\n",
    "        )\n",
    "    )\n",
    "    \n",
    "    # Debugging: Print the generated docstrings\n",
    "    print(data.loc[missing_values_mask, [new_docstring_col]])\n",
    "\n",
    "print(cb)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
