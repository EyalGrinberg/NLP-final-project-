{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting rouge-score\n",
      "  Downloading rouge_score-0.1.2.tar.gz (17 kB)\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "Collecting absl-py (from rouge-score)\n",
      "  Downloading absl_py-2.1.0-py3-none-any.whl (133 kB)\n",
      "                                              0.0/133.7 kB ? eta -:--:--\n",
      "     ---------                                30.7/133.7 kB ? eta -:--:--\n",
      "     --------------------------------       112.6/133.7 kB 1.3 MB/s eta 0:00:01\n",
      "     -------------------------------------- 133.7/133.7 kB 1.1 MB/s eta 0:00:00\n",
      "Collecting nltk (from rouge-score)\n",
      "  Downloading nltk-3.8.1-py3-none-any.whl (1.5 MB)\n",
      "                                              0.0/1.5 MB ? eta -:--:--\n",
      "     ----                                     0.2/1.5 MB 9.0 MB/s eta 0:00:01\n",
      "     -----------                              0.4/1.5 MB 5.3 MB/s eta 0:00:01\n",
      "     ---------------                          0.6/1.5 MB 4.7 MB/s eta 0:00:01\n",
      "     --------------------                     0.8/1.5 MB 4.3 MB/s eta 0:00:01\n",
      "     -------------------------------          1.2/1.5 MB 5.4 MB/s eta 0:00:01\n",
      "     ---------------------------------------- 1.5/1.5 MB 5.6 MB/s eta 0:00:00\n",
      "Requirement already satisfied: numpy in c:\\users\\shuni\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from rouge-score) (1.23.5)\n",
      "Requirement already satisfied: six>=1.14.0 in c:\\users\\shuni\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from rouge-score) (1.16.0)\n",
      "Collecting click (from nltk->rouge-score)\n",
      "  Downloading click-8.1.7-py3-none-any.whl (97 kB)\n",
      "                                              0.0/97.9 kB ? eta -:--:--\n",
      "     ---------------------------------------- 97.9/97.9 kB 5.5 MB/s eta 0:00:00\n",
      "Requirement already satisfied: joblib in c:\\users\\shuni\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from nltk->rouge-score) (1.2.0)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\shuni\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from nltk->rouge-score) (2023.12.25)\n",
      "Requirement already satisfied: tqdm in c:\\users\\shuni\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from nltk->rouge-score) (4.66.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\shuni\\appdata\\roaming\\python\\python310\\site-packages (from click->nltk->rouge-score) (0.4.6)\n",
      "Building wheels for collected packages: rouge-score\n",
      "  Building wheel for rouge-score (pyproject.toml): started\n",
      "  Building wheel for rouge-score (pyproject.toml): finished with status 'done'\n",
      "  Created wheel for rouge-score: filename=rouge_score-0.1.2-py3-none-any.whl size=24972 sha256=f36f0b8b83efaa835c997a8fd7b97aa22060fd01951fabb4c8ff6f8aa40051e3\n",
      "  Stored in directory: c:\\users\\shuni\\appdata\\local\\pip\\cache\\wheels\\5f\\dd\\89\\461065a73be61a532ff8599a28e9beef17985c9e9c31e541b4\n",
      "Successfully built rouge-score\n",
      "Installing collected packages: click, absl-py, nltk, rouge-score\n",
      "Successfully installed absl-py-2.1.0 click-8.1.7 nltk-3.8.1 rouge-score-0.1.2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.1.2 -> 24.0\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in c:\\users\\shuni\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (3.8.1)"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.1.2 -> 24.0\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Requirement already satisfied: click in c:\\users\\shuni\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from nltk) (8.1.7)\n",
      "Requirement already satisfied: joblib in c:\\users\\shuni\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from nltk) (1.2.0)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\shuni\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from nltk) (2023.12.25)\n",
      "Requirement already satisfied: tqdm in c:\\users\\shuni\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from nltk) (4.66.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\shuni\\appdata\\roaming\\python\\python310\\site-packages (from click->nltk) (0.4.6)\n"
     ]
    }
   ],
   "source": [
    "!pip install rouge-score\n",
    "!pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rouge_score import rouge_scorer\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_rouge(golden, generated):\n",
    "    scorer = rouge_scorer.RougeScorer(['rouge1', 'rouge2', 'rougeL'], use_stemmer=True)\n",
    "    return scorer.score(golden, generated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "generated_docstrings_data = pd.read_csv(\"function 10 all 3 models.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpt_docstring_function_10 = generated_docstrings_data.loc[10, \"GPT-3.5 Turbo\"]\n",
    "claude_docstring_function_10 = generated_docstrings_data.loc[10, \"claude\"]\n",
    "gemini_docstring_function_10 = generated_docstrings_data.loc[10, \"Gemini\"]\n",
    "\n",
    "golden_docstring_function_10 = generated_docstrings_data.loc[10, \"Golden Docstring\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'rouge1': Score(precision=0.8108108108108109, recall=0.8571428571428571, fmeasure=0.8333333333333334), 'rouge2': Score(precision=0.6944444444444444, recall=0.7352941176470589, fmeasure=0.7142857142857144), 'rougeL': Score(precision=0.7837837837837838, recall=0.8285714285714286, fmeasure=0.8055555555555555)}\n",
      "{'rouge1': Score(precision=0.417910447761194, recall=0.8, fmeasure=0.5490196078431372), 'rouge2': Score(precision=0.24242424242424243, recall=0.47058823529411764, fmeasure=0.32), 'rougeL': Score(precision=0.373134328358209, recall=0.7142857142857143, fmeasure=0.49019607843137253)}\n",
      "{'rouge1': Score(precision=0.8484848484848485, recall=0.8, fmeasure=0.823529411764706), 'rouge2': Score(precision=0.5625, recall=0.5294117647058824, fmeasure=0.5454545454545455), 'rougeL': Score(precision=0.696969696969697, recall=0.6571428571428571, fmeasure=0.676470588235294)}\n"
     ]
    }
   ],
   "source": [
    "print(evaluate_rouge(golden_docstring_function_10, gpt_docstring_function_10))\n",
    "print(evaluate_rouge(golden_docstring_function_10, claude_docstring_function_10))\n",
    "print(evaluate_rouge(golden_docstring_function_10, gemini_docstring_function_10))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Computes the difference between sparse matrices represented as dictionaries.\n",
      "    Args:\n",
      "    - lst (list): A list of dictionaries representing sparse matrices.\n",
      "    Returns:\n",
      "    - dict: A dictionary representing the result of the subtraction of all sparse matrices in the input list.\n"
     ]
    }
   ],
   "source": [
    "print(gpt_docstring_function_10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \"\"\"Iteratively computes the difference of sparse matrices stored in dictionaries by subtracting corresponding entries.\n",
      "\n",
      "Args:\n",
      "- lst (list): a list of dictionaries, where each dictionary represents a sparse matrix with integer entries. \n",
      "\n",
      "Returns: \n",
      "- dict: the dictionary representing the difference matrix, with entries corresponding to the subtraction of matrices in lst. Entries not present in all matrices will have the value of the negative entry from the subtracting matrix.\n",
      "\"\"\"\n"
     ]
    }
   ],
   "source": [
    "print(claude_docstring_function_10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "t5 = pd.read_csv(\"T5 BaseLine docstring generation.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = t5.loc[10, \"T5 BaseLine docstring generation\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'rouge1': Score(precision=0.8, recall=0.11428571428571428, fmeasure=0.19999999999999998),\n",
       " 'rouge2': Score(precision=0.5, recall=0.058823529411764705, fmeasure=0.10526315789473684),\n",
       " 'rougeL': Score(precision=0.8, recall=0.11428571428571428, fmeasure=0.19999999999999998)}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_rouge(golden_docstring_function_10, a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BLuE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have decided to use method5 as our smoothing funciton based on the results we've got when comparing to the other options and after reading 'A Systematic Comparison of Smoothing Techniques for Sentence-Level\n",
    "BLEU' by Boxing Chen and Colin Cherry.\n",
    "We've chosen it since it is quite intuitive and performs well for our purpouses - emphesizing meaning and recognizing the similarity between phrases even if there are slight variations or shifts in wording. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.translate.bleu_score import sentence_bleu, corpus_bleu, SmoothingFunction\n",
    "\n",
    "chencherry = SmoothingFunction()\n",
    "\n",
    "def get_bleu_score(ref, candidate):\n",
    "    return sentence_bleu([ref.split()], candidate.split(), smoothing_function=chencherry.method5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0004276919165459266\n",
      "0.5027541731081724\n",
      "0.2453357124137627\n",
      "0.42940530391199083\n"
     ]
    }
   ],
   "source": [
    "print(get_bleu_score(golden_docstring_function_10, a))\n",
    "print(get_bleu_score(golden_docstring_function_10, gpt_docstring_function_10))\n",
    "print(get_bleu_score(golden_docstring_function_10, claude_docstring_function_10))\n",
    "print(get_bleu_score(golden_docstring_function_10, gemini_docstring_function_10))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
